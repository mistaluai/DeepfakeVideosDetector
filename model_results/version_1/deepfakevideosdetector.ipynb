{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0004aad1",
   "metadata": {
    "papermill": {
     "duration": 0.004773,
     "end_time": "2025-02-20T01:06:06.725678",
     "exception": false,
     "start_time": "2025-02-20T01:06:06.720905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa5c4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:06.734974Z",
     "iopub.status.busy": "2025-02-20T01:06:06.734672Z",
     "iopub.status.idle": "2025-02-20T01:06:12.700621Z",
     "shell.execute_reply": "2025-02-20T01:06:12.699745Z"
    },
    "papermill": {
     "duration": 5.972421,
     "end_time": "2025-02-20T01:06:12.702216",
     "exception": false,
     "start_time": "2025-02-20T01:06:06.729795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyav\r\n",
      "  Downloading pyav-14.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\r\n",
      "Downloading pyav-14.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyav\r\n",
      "Successfully installed pyav-14.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23508cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:12.713126Z",
     "iopub.status.busy": "2025-02-20T01:06:12.712868Z",
     "iopub.status.idle": "2025-02-20T01:06:21.149372Z",
     "shell.execute_reply": "2025-02-20T01:06:21.148657Z"
    },
    "papermill": {
     "duration": 8.443648,
     "end_time": "2025-02-20T01:06:21.150973",
     "exception": false,
     "start_time": "2025-02-20T01:06:12.707325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, IterableDataset, get_worker_info\n",
    "from torchvision.datasets.folder import make_dataset\n",
    "from torchvision import transforms as t\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2\n",
    "from torch.jit import script, trace, trace_module\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98984cc",
   "metadata": {
    "papermill": {
     "duration": 0.004525,
     "end_time": "2025-02-20T01:06:21.160651",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.156126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a1d822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.170882Z",
     "iopub.status.busy": "2025-02-20T01:06:21.170501Z",
     "iopub.status.idle": "2025-02-20T01:06:21.176860Z",
     "shell.execute_reply": "2025-02-20T01:06:21.176032Z"
    },
    "papermill": {
     "duration": 0.013049,
     "end_time": "2025-02-20T01:06:21.178226",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.165177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainingUtilities:\n",
    "    @staticmethod\n",
    "    def save_model(model, model_descriptor, save_folder, verbose=0):\n",
    "        torch.save(model.state_dict(), save_folder + f\"/{model_descriptor}b1_model.pth\")\n",
    "        if verbose > 0:\n",
    "            print(f\"Saved model to {save_folder}/b1_model.pth\")\n",
    "\n",
    "    @staticmethod\n",
    "    def save_checkpoint(epoch, model_state_dict, optimizer_state_dict, scheduler_state_dict=None, save_folder='', verbose=0):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_state_dict,\n",
    "            'optimizer_state_dict': optimizer_state_dict,\n",
    "            'scheduler_state_dict': scheduler_state_dict\n",
    "        }\n",
    "        torch.save(checkpoint, save_folder + f'/checkpoint-epoch{epoch}.pth')\n",
    "        if verbose > 0:\n",
    "            print(f'Saved checkpoint to {save_folder}/checkpoint-epoch{epoch}.pth')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(model, optimizer, checkpoint_path, scheduled, verbose=0):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "\n",
    "        epoch = checkpoint['epoch']\n",
    "        model_state_dict = checkpoint['model_state_dict']\n",
    "        optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "        scheduler_state_dict = checkpoint['scheduler_state_dict']\n",
    "        model = model.load_state_dict(model_state_dict)\n",
    "        if scheduled:\n",
    "            optimizer.load_state_dict(optimizer_state_dict, scheduler_state_dict)\n",
    "        else:\n",
    "            optimizer = optimizer.load_state_dict(optimizer_state_dict)\n",
    "        return epoch, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdd98c",
   "metadata": {
    "papermill": {
     "duration": 0.004532,
     "end_time": "2025-02-20T01:06:21.187456",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.182924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6525ed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.197416Z",
     "iopub.status.busy": "2025-02-20T01:06:21.197157Z",
     "iopub.status.idle": "2025-02-20T01:06:21.209405Z",
     "shell.execute_reply": "2025-02-20T01:06:21.208828Z"
    },
    "papermill": {
     "duration": 0.018675,
     "end_time": "2025-02-20T01:06:21.210666",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.191991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_samples(root, extensions=(\".mp4\", \".avi\")):\n",
    "    samples = []\n",
    "\n",
    "    # Define class labels\n",
    "    class_to_idx = {\n",
    "        \"DFD_original sequences\": 0,  # Real videos\n",
    "        \"DFD_manipulated_sequences\": 1  # Deepfake videos\n",
    "    }\n",
    "\n",
    "    for class_name, label in class_to_idx.items():\n",
    "        class_dir = os.path.join(root, class_name)\n",
    "        if class_name == 'DFD_manipulated_sequences':\n",
    "            class_dir = os.path.join(class_dir, class_name)\n",
    "        print(class_dir)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "\n",
    "        # Get all video files in the directory\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith(extensions):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                samples.append((file_path, label))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "def get_datasets(root, splits, epoch_size=None, frame_transform=None, video_transform=None, clip_len=16, seed=2024):\n",
    "    train_split = splits[0]\n",
    "    val_split = splits[1]\n",
    "    test_split = splits[2]\n",
    "\n",
    "    samples = get_samples(root)\n",
    "    print(samples[0])\n",
    "    print(samples[-1])\n",
    "    \n",
    "    set_seed(seed, seed_torch=True)\n",
    "    random.shuffle(samples)\n",
    "\n",
    "    start, end = train_split\n",
    "    train_samples = samples[start:end]\n",
    "    start, end = val_split\n",
    "    val_samples = samples[start:end]\n",
    "    start, end = test_split\n",
    "    test_samples = samples[start:end]\n",
    "\n",
    "    train_dataset = VideosDataset(train_samples, frame_transform=frame_transform, video_transform=video_transform, clip_len=clip_len)\n",
    "    val_dataset = VideosDataset(val_samples, frame_transform=frame_transform, video_transform=video_transform, clip_len=clip_len)\n",
    "    test_dataset = VideosDataset(test_samples, frame_transform=frame_transform, video_transform=video_transform, clip_len=clip_len)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "\n",
    "class VideosDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, samples, epoch_size=None, frame_transform=None, video_transform=None, clip_len=16):\n",
    "        super(VideosDataset).__init__()\n",
    "        self.samples = samples\n",
    "\n",
    "        # Allow for temporal jittering\n",
    "        if epoch_size is None:\n",
    "            epoch_size = len(self.samples)\n",
    "        self.epoch_size = epoch_size\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "        if frame_transform is None:\n",
    "            self.frame_transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True), v2.Resize(255),\n",
    "                                 v2.CenterCrop(224)])\n",
    "        else:\n",
    "            self.frame_transform = frame_transform\n",
    "\n",
    "        self.video_transform = video_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "\n",
    "    def __pad_video(self, video_frames):\n",
    "        \"\"\"Prepad video frames to match clip length.\"\"\"\n",
    "        n = len(video_frames)\n",
    "        if n == self.clip_len:\n",
    "            return video_frames\n",
    "\n",
    "        # Create zero frames\n",
    "        pad_tensor = torch.zeros_like(video_frames[0])\n",
    "        pad_frames = [pad_tensor] * (self.clip_len - n)  # List of zero frames\n",
    "\n",
    "        return pad_frames + video_frames  # Prepadding at the beginning\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(self.epoch_size):\n",
    "            # Get random sample\n",
    "            path, target = random.choice(self.samples)\n",
    "            # Get video object\n",
    "            vid = torchvision.io.VideoReader(path, \"video\")\n",
    "            metadata = vid.get_metadata()\n",
    "            video_frames = []  # video frame buffer\n",
    "\n",
    "            for frame in itertools.islice(vid, self.clip_len):\n",
    "                video_frames.append(self.frame_transform(frame['data']))\n",
    "            video_frames = self.__pad_video(video_frames)\n",
    "            # Stack it into a tensor\n",
    "            video = torch.stack(video_frames, 0)\n",
    "            if self.video_transform:\n",
    "                video = self.video_transform(video)\n",
    "            output = {\n",
    "                'video': video,\n",
    "                'target': target\n",
    "            }\n",
    "            yield output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f13f8",
   "metadata": {
    "papermill": {
     "duration": 0.004407,
     "end_time": "2025-02-20T01:06:21.219625",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.215218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ca5002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.229529Z",
     "iopub.status.busy": "2025-02-20T01:06:21.229252Z",
     "iopub.status.idle": "2025-02-20T01:06:21.234819Z",
     "shell.execute_reply": "2025-02-20T01:06:21.234206Z"
    },
    "papermill": {
     "duration": 0.011869,
     "end_time": "2025-02-20T01:06:21.235984",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.224115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=512, num_layers=3, num_classes=2):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        cnn = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.feature_extractor = nn.Sequential(*list(cnn.children())[:-1])\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling to (B, 2048, 1, 1)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=2048, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, frames, C, H, W = x.shape  # (Batch, Frames, C, H, W)\n",
    "\n",
    "        x = x.view(batch_size * frames, C, H, W)  # (Batch × Frames, C, H, W)\n",
    "        features = self.feature_extractor(x)\n",
    "        features = self.pool(features).squeeze(-1).squeeze(-1)  # (Batch × Frames, 2048)\n",
    "\n",
    "        features = features.view(batch_size, frames, -1)  # (Batch, Frames, Feature_Dim)\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f47fa",
   "metadata": {
    "papermill": {
     "duration": 0.004354,
     "end_time": "2025-02-20T01:06:21.244947",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.240593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dbb97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.254873Z",
     "iopub.status.busy": "2025-02-20T01:06:21.254627Z",
     "iopub.status.idle": "2025-02-20T01:06:21.258683Z",
     "shell.execute_reply": "2025-02-20T01:06:21.258086Z"
    },
    "papermill": {
     "duration": 0.010373,
     "end_time": "2025-02-20T01:06:21.259841",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.249468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, class_real=364, class_fake=3068):\n",
    "        super(Loss, self).__init__()\n",
    "        num_samples = class_real + class_fake\n",
    "        self.real_weight = num_samples / (2 * class_real)\n",
    "        self.fake_weight = num_samples / (2 * class_fake)\n",
    "        weights = torch.tensor([self.real_weight, self.fake_weight], dtype=torch.float)\n",
    "        self.loss = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        return self.loss(outputs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f7bcd6",
   "metadata": {
    "papermill": {
     "duration": 0.004365,
     "end_time": "2025-02-20T01:06:21.268837",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.264472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a9b6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.278896Z",
     "iopub.status.busy": "2025-02-20T01:06:21.278632Z",
     "iopub.status.idle": "2025-02-20T01:06:21.295012Z",
     "shell.execute_reply": "2025-02-20T01:06:21.294444Z"
    },
    "papermill": {
     "duration": 0.022896,
     "end_time": "2025-02-20T01:06:21.296218",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.273322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, optimizer, scheduled, criterion, epochs, dataloaders, device, save_folder,\n",
    "                 is_continue=False, checkpoint=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduled = scheduled\n",
    "        self.criterion = criterion\n",
    "        self.epochs = epochs\n",
    "        self.dataloaders = dataloaders\n",
    "        self.DEVICE = device\n",
    "        self.save_folder = save_folder\n",
    "        self.is_continue = is_continue\n",
    "        self.checkpoint = checkpoint\n",
    "        self.scaler = torch.amp.GradScaler()\n",
    "\n",
    "    def train_model(self, verbose=0):\n",
    "        model, optimizer, criterion, epochs, dataloaders = self.model, self.optimizer, self.criterion, self.epochs, self.dataloaders\n",
    "        device = self.DEVICE\n",
    "        scaler = self.scaler\n",
    "        training_epoch = 0\n",
    "        epoch = 0\n",
    "        if self.is_continue:\n",
    "\n",
    "            if verbose > 0:\n",
    "                print(f\"Continuing from checkpoint {self.checkpoint}\")\n",
    "\n",
    "            epoch, model, optimizer = TrainingUtilities.load_checkpoint(model, optimizer, self.checkpoint, self.scheduled, verbose)\n",
    "        \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        test_losses = []\n",
    "\n",
    "        val_accuracies = []\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        \n",
    "        for training_epoch in range(epoch, epochs):\n",
    "            print(f\"\\nTraining epoch {training_epoch+1}\")\n",
    "           \n",
    "\n",
    "            avg_train_loss = 0\n",
    "            avg_val_loss = 0\n",
    "            val_accuracy = 0\n",
    "            train_accuracy = 0\n",
    "            train_time = 0\n",
    "            val_time = 0\n",
    "            val_f1 = 0\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    start_time = time.time()\n",
    "                    # print(\"Training phase.....\")\n",
    "                    train_loader = dataloaders['train']\n",
    "                    model.train()\n",
    "                    train_loss = 0\n",
    "                    correct_train = 0\n",
    "                    total_train = 0\n",
    "                    for batch in train_loader:\n",
    "                        video = batch['video'].to(device)  # (Batch, Frames, C, H, W)\n",
    "                        target = batch['target'].to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        with torch.amp.autocast('cuda'):\n",
    "                            outputs = model(video)\n",
    "                            loss = criterion(outputs, target)\n",
    "\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                        train_loss += loss.item()\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        correct_train += (predicted == target).sum().item()\n",
    "                        total_train += target.size(0)\n",
    "\n",
    "                    avg_train_loss = train_loss / len(train_loader)\n",
    "                    train_accuracy = correct_train / total_train\n",
    "                    end_time = time.time()\n",
    "                    train_time = end_time - start_time\n",
    "                    formatted_time = time.strftime(\"%Mmins %Ssecs\", time.gmtime(train_time))\n",
    "                    print(f\"Training completed in {formatted_time}\")\n",
    "                else:\n",
    "                    # print(\"Validation phase.....\")\n",
    "                    val_loader = dataloaders['val']\n",
    "                    start_time = time.time()\n",
    "                    avg_val_loss, val_accuracy, val_f1 = self.evaluate(val_loader, training_epoch)\n",
    "                    end_time = time.time()\n",
    "                    val_time = end_time - start_time\n",
    "                    formatted_time = time.strftime(\"%Mmins %Ssecs\", time.gmtime(val_time))\n",
    "                    print(f\"Validation completed in {formatted_time}\")\n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(\n",
    "                f\"Epoch [{training_epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\"\n",
    "            )\n",
    "            start_time = time.time()\n",
    "            avg_test_loss, test_accuracy = self.test(dataloaders['test'], training_epoch+1)\n",
    "            end_time = time.time()\n",
    "            test_time = end_time - start_time\n",
    "            formatted_time = time.strftime(\"%Mmins %Ssecs\", time.gmtime(test_time))\n",
    "            print(f\"Testing completed in {formatted_time}\")\n",
    "            test_losses.append(avg_test_loss)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        return train_losses, val_losses, test_losses, train_accuracies, val_accuracies, test_accuracies\n",
    "\n",
    "    def test(self, test_loader, epoch):\n",
    "        model, criterion, device = self.model, self.criterion, self.DEVICE\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                for batch in test_loader:\n",
    "                    video = batch['video'].to(device)\n",
    "                    target = batch['target'].to(device)\n",
    "\n",
    "                    outputs = model(video)\n",
    "                    loss = criterion(outputs, target)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct_test += (predicted == target).sum().item()\n",
    "                    total_test += target.size(0)\n",
    "\n",
    "                    # Store predictions and true labels for F1-score\n",
    "                    y_true.extend(target.cpu().numpy())\n",
    "                    y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "        TrainingUtilities.save_model(model, f'model_epoch{epoch}-acc{test_accuracy:.2f}', self.save_folder)\n",
    "        return avg_test_loss, test_accuracy\n",
    "\n",
    "    def evaluate(self, val_loader, epoch, verbose=0):\n",
    "        model, criterion, device = self.model, self.criterion, self.DEVICE\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                for batch in val_loader:\n",
    "                    video = batch['video'].to(device)\n",
    "                    target = batch['target'].to(device)\n",
    "\n",
    "                    outputs = model(video)\n",
    "                    loss = criterion(outputs, target)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct_val += (predicted == target).sum().item()\n",
    "                    total_val += target.size(0)\n",
    "\n",
    "                    # Store predictions and true labels for F1-score\n",
    "                    y_true.extend(target.cpu().numpy())\n",
    "                    y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_accuracy = correct_val / total_val\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        return avg_val_loss, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1ae97",
   "metadata": {
    "papermill": {
     "duration": 0.004429,
     "end_time": "2025-02-20T01:06:21.305307",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.300878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18d1992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.315423Z",
     "iopub.status.busy": "2025-02-20T01:06:21.315150Z",
     "iopub.status.idle": "2025-02-20T01:06:21.443755Z",
     "shell.execute_reply": "2025-02-20T01:06:21.442822Z"
    },
    "papermill": {
     "duration": 0.135109,
     "end_time": "2025-02-20T01:06:21.445080",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.309971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_original sequences\n",
      "/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_manipulated_sequences/DFD_manipulated_sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3431"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root = \"/kaggle/input/deep-fake-detection-dfd-entire-original-dataset\"\n",
    "dataset_size = len(get_samples(dataset_root))\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61caabcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.456553Z",
     "iopub.status.busy": "2025-02-20T01:06:21.456240Z",
     "iopub.status.idle": "2025-02-20T01:06:21.460721Z",
     "shell.execute_reply": "2025-02-20T01:06:21.459908Z"
    },
    "papermill": {
     "duration": 0.011307,
     "end_time": "2025-02-20T01:06:21.461947",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.450640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 2401, test: 514, val: 516\n"
     ]
    }
   ],
   "source": [
    "# Define split sizes\n",
    "train_size = int(0.7 * dataset_size)  # 70% for training\n",
    "val_size = int(0.15 * dataset_size)   # 15% for validation\n",
    "test_size = dataset_size - train_size - val_size  # 15% for testing\n",
    "\n",
    "print(f'train: {train_size}, test: {val_size}, val: {test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e046a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.472633Z",
     "iopub.status.busy": "2025-02-20T01:06:21.472384Z",
     "iopub.status.idle": "2025-02-20T01:06:21.493773Z",
     "shell.execute_reply": "2025-02-20T01:06:21.492806Z"
    },
    "papermill": {
     "duration": 0.028085,
     "end_time": "2025-02-20T01:06:21.494967",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.466882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_original sequences\n",
      "/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_manipulated_sequences/DFD_manipulated_sequences\n",
      "('/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_original sequences/26__walking_down_street_outside_angry.mp4', 0)\n",
      "('/kaggle/input/deep-fake-detection-dfd-entire-original-dataset/DFD_manipulated_sequences/DFD_manipulated_sequences/06_02__exit_phone_room__3J3BHSHI.mp4', 1)\n",
      "Random seed 2024 has been set.\n",
      "train: 2401, test: 514, val: 516\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "train_split = (0,train_size)\n",
    "val_split = (train_size, val_size + train_size)\n",
    "test_split = (val_size + train_size, val_size + train_size + test_size)\n",
    "\n",
    "splits = [train_split, val_split, test_split]\n",
    "frames= 10\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(root=dataset_root,splits=splits, clip_len=frames)\n",
    "# train_dataset = RandomDataset(root=dataset_root, clip_len=frames, split=train_split)\n",
    "# val_dataset = RandomDataset(root=dataset_root, clip_len=frames, split=val_split)\n",
    "# test_dataset = RandomDataset(root=dataset_root, clip_len=frames, split=test_split)\n",
    "\n",
    "batch_size = 30\n",
    "print(f'train: {train_dataset.__len__()}, test: {val_dataset.__len__()}, val: {test_dataset.__len__()}')# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,drop_last=True)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbef5951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.505566Z",
     "iopub.status.busy": "2025-02-20T01:06:21.505315Z",
     "iopub.status.idle": "2025-02-20T01:06:21.558887Z",
     "shell.execute_reply": "2025-02-20T01:06:21.557980Z"
    },
    "papermill": {
     "duration": 0.060287,
     "end_time": "2025-02-20T01:06:21.560276",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.499989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95fe50c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:21.571677Z",
     "iopub.status.busy": "2025-02-20T01:06:21.571399Z",
     "iopub.status.idle": "2025-02-20T01:06:23.059825Z",
     "shell.execute_reply": "2025-02-20T01:06:23.059066Z"
    },
    "papermill": {
     "duration": 1.495561,
     "end_time": "2025-02-20T01:06:23.061480",
     "exception": false,
     "start_time": "2025-02-20T01:06:21.565919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 206MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = CNN_LSTM().to(device)\n",
    "criterion = Loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8cf70c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:23.074182Z",
     "iopub.status.busy": "2025-02-20T01:06:23.073782Z",
     "iopub.status.idle": "2025-02-20T01:06:23.078227Z",
     "shell.execute_reply": "2025-02-20T01:06:23.077373Z"
    },
    "papermill": {
     "duration": 0.012239,
     "end_time": "2025-02-20T01:06:23.079519",
     "exception": false,
     "start_time": "2025-02-20T01:06:23.067280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_folder = '/kaggle/working/'\n",
    "trainer = ModelTrainer(model=model, optimizer=optimizer, criterion=criterion, epochs=10, dataloaders=dataloaders, device=device, save_folder=save_folder, scheduled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1444f57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T01:06:23.091270Z",
     "iopub.status.busy": "2025-02-20T01:06:23.091009Z",
     "iopub.status.idle": "2025-02-20T03:39:27.015911Z",
     "shell.execute_reply": "2025-02-20T03:39:27.014836Z"
    },
    "papermill": {
     "duration": 9183.932068,
     "end_time": "2025-02-20T03:39:27.017198",
     "exception": false,
     "start_time": "2025-02-20T01:06:23.085130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch 1\n",
      "Training completed in 11mins 35secs\n",
      "Validation completed in 02mins 11secs\n",
      "Epoch [1/10], Train Loss: 0.8080, Train Acc: 0.5579, Val Loss: 1.0230, Val Acc: 0.6706, Val F1: 0.7325\n",
      "Test Loss: 1.0325, Test Accuracy: 0.7000, Test F1 Score: 0.7766\n",
      "Testing completed in 02mins 13secs\n",
      "\n",
      "Training epoch 2\n",
      "Training completed in 11mins 23secs\n",
      "Validation completed in 02mins 04secs\n",
      "Epoch [2/10], Train Loss: 0.7628, Train Acc: 0.5696, Val Loss: 0.9622, Val Acc: 0.5196, Val F1: 0.6057\n",
      "Test Loss: 1.0027, Test Accuracy: 0.5667, Test F1 Score: 0.6671\n",
      "Testing completed in 02mins 09secs\n",
      "\n",
      "Training epoch 3\n",
      "Training completed in 10mins 49secs\n",
      "Validation completed in 02mins 01secs\n",
      "Epoch [3/10], Train Loss: 0.7562, Train Acc: 0.6554, Val Loss: 0.7001, Val Acc: 0.8980, Val F1: 0.8498\n",
      "Test Loss: 0.8320, Test Accuracy: 0.9314, Test F1 Score: 0.8983\n",
      "Testing completed in 02mins 04secs\n",
      "\n",
      "Training epoch 4\n",
      "Training completed in 10mins 59secs\n",
      "Validation completed in 02mins 05secs\n",
      "Epoch [4/10], Train Loss: 0.7679, Train Acc: 0.4025, Val Loss: 0.7153, Val Acc: 0.1020, Val F1: 0.0189\n",
      "Test Loss: 0.7306, Test Accuracy: 0.0922, Test F1 Score: 0.0192\n",
      "Testing completed in 02mins 07secs\n",
      "\n",
      "Training epoch 5\n",
      "Training completed in 10mins 55secs\n",
      "Validation completed in 02mins 02secs\n",
      "Epoch [5/10], Train Loss: 0.7315, Train Acc: 0.5817, Val Loss: 0.7902, Val Acc: 0.1412, Val F1: 0.0441\n",
      "Test Loss: 0.9152, Test Accuracy: 0.0588, Test F1 Score: 0.0065\n",
      "Testing completed in 02mins 02secs\n",
      "\n",
      "Training epoch 6\n",
      "Training completed in 10mins 53secs\n",
      "Validation completed in 02mins 04secs\n",
      "Epoch [6/10], Train Loss: 0.7427, Train Acc: 0.6683, Val Loss: 0.7162, Val Acc: 0.8843, Val F1: 0.8300\n",
      "Test Loss: 0.6682, Test Accuracy: 0.9235, Test F1 Score: 0.8868\n",
      "Testing completed in 02mins 04secs\n",
      "\n",
      "Training epoch 7\n",
      "Training completed in 11mins 05secs\n",
      "Validation completed in 02mins 10secs\n",
      "Epoch [7/10], Train Loss: 0.7169, Train Acc: 0.6571, Val Loss: 2.5736, Val Acc: 0.8608, Val F1: 0.7964\n",
      "Test Loss: 1.6274, Test Accuracy: 0.9275, Test F1 Score: 0.8925\n",
      "Testing completed in 02mins 12secs\n",
      "\n",
      "Training epoch 8\n",
      "Training completed in 11mins 23secs\n",
      "Validation completed in 02mins 08secs\n",
      "Epoch [8/10], Train Loss: 0.6880, Train Acc: 0.8287, Val Loss: 30.0352, Val Acc: 0.8745, Val F1: 0.8160\n",
      "Test Loss: 20.5032, Test Accuracy: 0.9314, Test F1 Score: 0.8983\n",
      "Testing completed in 02mins 09secs\n",
      "\n",
      "Training epoch 9\n",
      "Training completed in 11mins 06secs\n",
      "Validation completed in 02mins 01secs\n",
      "Epoch [9/10], Train Loss: 0.6798, Train Acc: 0.8213, Val Loss: 5.6943, Val Acc: 0.9078, Val F1: 0.8640\n",
      "Test Loss: 5.0227, Test Accuracy: 0.9216, Test F1 Score: 0.8840\n",
      "Testing completed in 02mins 02secs\n",
      "\n",
      "Training epoch 10\n",
      "Training completed in 10mins 49secs\n",
      "Validation completed in 02mins 02secs\n",
      "Epoch [10/10], Train Loss: 0.6796, Train Acc: 0.8333, Val Loss: 27.1460, Val Acc: 0.8706, Val F1: 0.8104\n",
      "Test Loss: 20.2702, Test Accuracy: 0.9157, Test F1 Score: 0.8754\n",
      "Testing completed in 02mins 02secs\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, test_losses, train_accuracies, val_accuracies, test_accuracies = trainer.train_model(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e49ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T03:39:27.032214Z",
     "iopub.status.busy": "2025-02-20T03:39:27.031960Z",
     "iopub.status.idle": "2025-02-20T03:39:27.039253Z",
     "shell.execute_reply": "2025-02-20T03:39:27.038342Z"
    },
    "papermill": {
     "duration": 0.016196,
     "end_time": "2025-02-20T03:39:27.040401",
     "exception": false,
     "start_time": "2025-02-20T03:39:27.024205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, save_dir=\"plots\"):\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def plot_loss(self, train_loss, val_loss, test_loss=None, filename=\"loss_plot.png\"):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(train_loss, label=\"Train Loss\", marker='o')\n",
    "        plt.plot(val_loss, label=\"Validation Loss\", marker='o')\n",
    "        if test_loss is not None:\n",
    "            plt.plot(test_loss, label=\"Test Loss\", marker='o')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training, Validation, and Test Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        save_path = os.path.join(self.save_dir, filename)\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Loss plot saved to {save_path}\")\n",
    "\n",
    "    def plot_accuracy(self, train_acc, val_acc, test_acc=None, filename=\"accuracy_plot.png\"):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(train_acc, label=\"Train Accuracy\", marker='o')\n",
    "        plt.plot(val_acc, label=\"Validation Accuracy\", marker='o')\n",
    "        if test_acc is not None:\n",
    "            plt.plot(test_acc, label=\"Test Accuracy\", marker='o')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Training, Validation, and Test Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        save_path = os.path.join(self.save_dir, filename)\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Accuracy plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc8359c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T03:39:27.054599Z",
     "iopub.status.busy": "2025-02-20T03:39:27.054365Z",
     "iopub.status.idle": "2025-02-20T03:39:27.439558Z",
     "shell.execute_reply": "2025-02-20T03:39:27.438524Z"
    },
    "papermill": {
     "duration": 0.393605,
     "end_time": "2025-02-20T03:39:27.440801",
     "exception": false,
     "start_time": "2025-02-20T03:39:27.047196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss plot saved to /kaggle/working/loss_plot.png\n",
      "Accuracy plot saved to /kaggle/working/accuracy_plot.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot = Plotter(save_dir='/kaggle/working/')\n",
    "plot.plot_loss(train_loss=train_losses, val_loss=val_losses, test_loss=test_losses)\n",
    "plot.plot_accuracy(train_acc=train_accuracies, val_acc=val_accuracies, test_acc=test_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5524489,
     "sourceId": 9146200,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9206.287368,
   "end_time": "2025-02-20T03:39:30.365855",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-20T01:06:04.078487",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
